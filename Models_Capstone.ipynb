{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNeRD83VZy8TFEo4F13JjT5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["pip install ngboost scikit-learn"],"metadata":{"id":"EcgiI2w_3OcG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743797639422,"user_tz":240,"elapsed":9360,"user":{"displayName":"Gus Weyand","userId":"01199470030754915479"}},"outputId":"77b5950c-5ad7-4a3a-8a62-b94591ec1f31"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ngboost\n","  Downloading ngboost-0.5.5-py3-none-any.whl.metadata (4.0 kB)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n","Collecting lifelines>=0.25 (from ngboost)\n","  Downloading lifelines-0.30.0-py3-none-any.whl.metadata (3.2 kB)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from ngboost) (2.0.2)\n","Requirement already satisfied: scipy>=1.7.2 in /usr/local/lib/python3.11/dist-packages (from ngboost) (1.14.1)\n","Requirement already satisfied: tqdm>=4.3 in /usr/local/lib/python3.11/dist-packages (from ngboost) (4.67.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.11/dist-packages (from lifelines>=0.25->ngboost) (2.2.2)\n","Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.11/dist-packages (from lifelines>=0.25->ngboost) (3.10.0)\n","Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.11/dist-packages (from lifelines>=0.25->ngboost) (1.7.0)\n","Collecting autograd-gamma>=0.3 (from lifelines>=0.25->ngboost)\n","  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting formulaic>=0.2.2 (from lifelines>=0.25->ngboost)\n","  Downloading formulaic-1.1.1-py3-none-any.whl.metadata (6.9 kB)\n","Collecting interface-meta>=1.2.0 (from formulaic>=0.2.2->lifelines>=0.25->ngboost)\n","  Downloading interface_meta-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from formulaic>=0.2.2->lifelines>=0.25->ngboost) (4.13.0)\n","Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.11/dist-packages (from formulaic>=0.2.2->lifelines>=0.25->ngboost) (1.17.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (4.56.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (11.1.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->lifelines>=0.25->ngboost) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->lifelines>=0.25->ngboost) (2025.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines>=0.25->ngboost) (1.17.0)\n","Downloading ngboost-0.5.5-py3-none-any.whl (33 kB)\n","Downloading lifelines-0.30.0-py3-none-any.whl (349 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.3/349.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading formulaic-1.1.1-py3-none-any.whl (115 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.7/115.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n","Building wheels for collected packages: autograd-gamma\n","  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4030 sha256=3d52e4fb57ce89c1c20182bb517e978446085bbd50d61e312f76b5e48a339597\n","  Stored in directory: /root/.cache/pip/wheels/8b/67/f4/2caaae2146198dcb824f31a303833b07b14a5ec863fb3acd7b\n","Successfully built autograd-gamma\n","Installing collected packages: interface-meta, autograd-gamma, formulaic, lifelines, ngboost\n","Successfully installed autograd-gamma-0.5.0 formulaic-1.1.1 interface-meta-1.3.0 lifelines-0.30.0 ngboost-0.5.5\n"]}]},{"cell_type":"code","source":["pip install lightgbm optuna"],"metadata":{"id":"m4SrN6FK3OfM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743797651264,"user_tz":240,"elapsed":11840,"user":{"displayName":"Gus Weyand","userId":"01199470030754915479"}},"outputId":"4f87705e-2ff6-49d1-bae6-b958a376e5fc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.5.0)\n","Collecting optuna\n","  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n","Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from lightgbm) (2.0.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.14.1)\n","Collecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n","Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n","Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.0)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n","Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n","Installing collected packages: colorlog, alembic, optuna\n","Successfully installed alembic-1.15.2 colorlog-6.9.0 optuna-4.2.1\n"]}]},{"cell_type":"code","source":["from google.colab import auth\n","auth.authenticate_user()"],"metadata":{"id":"una9sF_pE2tH","executionInfo":{"status":"error","timestamp":1743797661227,"user_tz":240,"elapsed":9964,"user":{"displayName":"Gus Weyand","userId":"01199470030754915479"}},"colab":{"base_uri":"https://localhost:8080/","height":311},"outputId":"5569b02b-ef48-4a07-8879-428f85eee91a"},"execution_count":null,"outputs":[{"output_type":"error","ename":"MessageError","evalue":"Error: credential propagation was unsuccessful","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-1f759c1655bd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthenticate_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/auth.py\u001b[0m in \u001b[0;36mauthenticate_user\u001b[0;34m(clear_output, project_id)\u001b[0m\n\u001b[1;32m    258\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_check_adc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_CredentialType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUSER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_auth_ephem\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m       _message.blocking_request(\n\u001b[0m\u001b[1;32m    261\u001b[0m           \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m           \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'auth_user_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}]},{"cell_type":"code","source":["from joblib import dump, load\n","\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"6cnff-cLx0au"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import PCA\n","\n","df = pd.read_csv('PCA_df_w_game_markersUPDATED.csv')"],"metadata":{"id":"f_01pUlr3OiB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"id":"24MGZCvvxvzR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.info()"],"metadata":{"id":"eQuNpU3HWBbT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Assuming 'Date' is your column containing the date in datetime format\n","df['gameDate'] = pd.to_datetime(df['gameDate'])  # Ensure the 'Date' column is in datetime format\n","target = 'win_indicator'\n","# Define the threshold date (July 1st, 2022)\n","threshold_date = pd.Timestamp('2022-07-01')\n","\n","# Split the data into training and testing sets\n","train_df = df[df['gameDate'] < threshold_date]  # Data before July 1st, 2022 for training\n","test_df = df[df['gameDate'] >= threshold_date]  # Data after July 1st, 2022 for testing\n","\n","# Separate features and target for training\n","X_train = train_df.drop(columns=[target, 'win_indicator'])  # Exclude target and Date columns\n","y_train = train_df[target]\n","\n","# Separate features and target for testing\n","X_test = test_df.drop(columns=[target, 'win_indicator'])  # Exclude target and Date columns\n","y_test = test_df[target]\n","\n","# Save the training and test sets to CSV files (optional)\n","train_df.to_csv(\"train_data_NHL.csv\", index=False)\n","test_df.to_csv(\"test_data_NHL.csv\", index=False)\n","\n","# Display a few rows of each set for confirmation\n","print(\"Training Data:\")\n","print(train_df.head())\n","print(len(train_df))\n","print(\"\\nTest Data:\")\n","print(test_df.head())\n","print(len(test_df))\n"],"metadata":{"id":"N9q-OFCCWBdp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train.head()"],"metadata":{"id":"_UiyHJPHYBET"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df.head()"],"metadata":{"id":"NzOgqt7JYBGZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_df.head()"],"metadata":{"id":"K6KxzMUtY1K9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train = X_train.drop(['season', 'name', 'opposingTeam', 'Game_Number', 'gameDate'], axis=1)\n","X_test = X_test.drop(['season', 'name', 'opposingTeam', 'Game_Number', 'gameDate'], axis=1)"],"metadata":{"id":"O604qX9KWBgP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train.head()"],"metadata":{"id":"OvA5jDO5x9LP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df.head()"],"metadata":{"id":"5B7Sazgja2AS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"aqvCqv3ia2CX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"TmkUCkj9a2FA"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vpzSEJ-txi0W"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import train_test_split, RandomizedSearchCV\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n","from joblib import dump\n","\n","# Define hyperparameter grid\n","param_grid = {\n","    \"n_estimators\": [50, 75, 100, 125],  # Number of trees\n","    \"max_depth\": [10, 15, 20, 25],  # Maximum depth of trees\n","    \"min_samples_split\": [10, 15, 20, 30],  # Minimum samples required to split a node\n","    \"min_samples_leaf\": [5, 10, 12, 14, 16],  # Minimum samples per leaf node\n","    \"max_features\": [\"sqrt\", \"log2\"]  # Number of features per split\n","}\n","\n","# Initialize the Random Forest classifier\n","rf = RandomForestClassifier(random_state=42)\n","\n","# Perform Randomized Search with 5-fold cross-validation\n","rf_search = RandomizedSearchCV(\n","    estimator=rf,\n","    param_distributions=param_grid,\n","    n_iter=20,  # Number of random combinations to try\n","    cv=5,  # 5-fold cross-validation\n","    verbose=2,\n","    n_jobs=-1,  # Use all available processors\n","    random_state=42\n",")\n","\n","# Fit the model with the best parameters\n","rf_search.fit(X_train, y_train)\n","best_rf = rf_search.best_estimator_\n","\n","# Make predictions\n","y_pred_train = best_rf.predict(X_train)\n","y_pred_test = best_rf.predict(X_test)\n","\n","# Model evaluation\n","accuracy_train = accuracy_score(y_train, y_pred_train)\n","accuracy_test = accuracy_score(y_test, y_pred_test)\n","precision_test = precision_score(y_test, y_pred_test, average='binary')\n","recall_test = recall_score(y_test, y_pred_test, average='binary')\n","f1_test = f1_score(y_test, y_pred_test, average='binary')\n","conf_matrix = confusion_matrix(y_test, y_pred_test)\n","class_report = classification_report(y_test, y_pred_test)\n","\n","# Print results\n","print(\"Best Parameters:\", rf_search.best_params_)\n","print(\"\\nTrain Performance:\")\n","print(f\"  Accuracy: {accuracy_train:.4f}\")\n","print(\"\\nTest Performance:\")\n","print(f\"  Accuracy: {accuracy_test:.4f}\")\n","print(f\"  Precision: {precision_test:.4f}\")\n","print(f\"  Recall: {recall_test:.4f}\")\n","print(f\"  F1 Score: {f1_test:.4f}\")\n","print(\"\\nConfusion Matrix:\")\n","print(conf_matrix)\n","print(\"\\nClassification Report:\")\n","print(class_report)\n","\n","# Add predictions to DataFrame\n","#df[\"Predicted_wins\"] = best_rf.predict(X)\n","\n","dump(best_rf, '/content/drive/My Drive/SLMg77/Models/RF_model_thesis_Classification.joblib')\n"]},{"cell_type":"code","source":["dump(best_rf, '/content/drive/My Drive/SLMg77/Models/RF_model_thesis_Classification.joblib')"],"metadata":{"id":"qeJwktogksCP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head(30)\n"],"metadata":{"id":"6LMeNmoxUv-S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"nQw3-1kgUwAm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"SYP9LaoAUwC9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"x5RjRod2UwFB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"dDlHL_rxUwHX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"mwj2unOEUwJv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"mgkoOQwEUwMD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"UeTHrQcIUwOK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"aYwtIEc8UwQf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from xgboost import XGBClassifier\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n","from joblib import dump\n","\n","# Define XGBoost model\n","xgb_model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n","\n","# Define hyperparameter grid\n","param_grid = {\n","    'n_estimators': [100, 150, 200, 250],\n","    'max_depth': [3, 4],\n","    'learning_rate': [0.1, 0.01, 0.001, 0.05],\n","    'subsample': [0.6, 0.75, 0.9],\n","    'colsample_bytree': [0.7, 0.8, 0.9]\n","}\n","\n","# GridSearch for hyperparameter tuning\n","grid_search_xgb = GridSearchCV(\n","    estimator=xgb_model,\n","    param_grid=param_grid,\n","    cv=5,\n","    scoring='accuracy',\n","    n_jobs=-1,\n","    verbose=2\n",")\n","\n","# Fit the model using the existing X_train, y_train\n","grid_search_xgb.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=True)\n","\n","# Get the best model\n","best_xgb_model = grid_search_xgb.best_estimator_\n","\n","# Predictions\n","y_pred_train_xgb = best_xgb_model.predict(X_train)\n","y_pred_test_xgb = best_xgb_model.predict(X_test)\n","\n","# Model evaluation\n","accuracy_train_xgb = accuracy_score(y_train, y_pred_train_xgb)\n","accuracy_test_xgb = accuracy_score(y_test, y_pred_test_xgb)\n","precision_test_xgb = precision_score(y_test, y_pred_test_xgb, average='binary')\n","recall_test_xgb = recall_score(y_test, y_pred_test_xgb, average='binary')\n","f1_test_xgb = f1_score(y_test, y_pred_test_xgb, average='binary')\n","conf_matrix_xgb = confusion_matrix(y_test, y_pred_test_xgb)\n","class_report_xgb = classification_report(y_test, y_pred_test_xgb)\n","\n","# Print results\n","print(\"Best Parameters:\", grid_search_xgb.best_params_)\n","print(\"\\nTrain Performance:\")\n","print(f\"  Accuracy: {accuracy_train_xgb:.4f}\")\n","print(\"\\nTest Performance:\")\n","print(f\"  Accuracy: {accuracy_test_xgb:.4f}\")\n","print(f\"  Precision: {precision_test_xgb:.4f}\")\n","print(f\"  Recall: {recall_test_xgb:.4f}\")\n","print(f\"  F1 Score: {f1_test_xgb:.4f}\")\n","print(\"\\nConfusion Matrix:\")\n","print(conf_matrix_xgb)\n","print(\"\\nClassification Report:\")\n","print(class_report_xgb)\n","\n","# Save the best model\n","dump(best_xgb_model, '/content/drive/My Drive/SLMg77/Models/XGB_model_thesis_Classification.joblib')\n","\n","print(\"\\nXGBoost model saved\")\n"],"metadata":{"id":"B5PnACECwqpw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ufB6f8EGy3_1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JxbKqaS5wqsF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train.head()"],"metadata":{"id":"qeKDbd9Pwqub"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n","from ngboost import NGBClassifier\n","from ngboost.distns import Bernoulli  # Use Bernoulli for classification\n","from joblib import dump\n","\n","# Define the model (with Bernoulli for classification)\n","ngb = NGBClassifier(Dist=Bernoulli)\n","\n","# Define parameter grid for classification\n","param_grid = {\n","    'n_estimators': [100, 150, 200, 250],\n","    'learning_rate': [0.01, 0.05, 0.1],\n","    'minibatch_frac': [0.5, 0.8, 1.0],\n","    'natural_gradient': [True, False]\n","}\n","\n","# Grid search with classification metrics\n","grid_search = GridSearchCV(ngb, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n","grid_search.fit(X_train, y_train)\n","\n","# Best parameters\n","print(\"Best Parameters:\", grid_search.best_params_)\n","\n","# Best model predictions\n","best_ngb = grid_search.best_estimator_\n","y_pred_train = best_ngb.predict(X_train)\n","y_pred_test = best_ngb.predict(X_test)\n","\n","# Evaluate model\n","accuracy_train = accuracy_score(y_train, y_pred_train)\n","accuracy_test = accuracy_score(y_test, y_pred_test)\n","precision_test = precision_score(y_test, y_pred_test, average='binary')\n","recall_test = recall_score(y_test, y_pred_test, average='binary')\n","f1_test = f1_score(y_test, y_pred_test, average='binary')\n","conf_matrix = confusion_matrix(y_test, y_pred_test)\n","class_report = classification_report(y_test, y_pred_test)\n","\n","# Print results\n","print(\"\\nTrain Performance:\")\n","print(f\"  Accuracy: {accuracy_train:.4f}\")\n","print(\"\\nTest Performance:\")\n","print(f\"  Accuracy: {accuracy_test:.4f}\")\n","print(f\"  Precision: {precision_test:.4f}\")\n","print(f\"  Recall: {recall_test:.4f}\")\n","print(f\"  F1 Score: {f1_test:.4f}\")\n","print(\"\\nConfusion Matrix:\")\n","print(conf_matrix)\n","print(\"\\nClassification Report:\")\n","print(class_report)\n","\n","\n","dump(best_ngb, '/content/drive/My Drive/SLMg77/Models/NGB_model_thesis_Classification.joblib')\n","\n","\n","print(\"\\nModel saved\")\n","\n","\n"],"metadata":{"id":"kpZh3pBSx0hu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"wt6RT-7twroC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JO4yAiIYwrqU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n"],"metadata":{"id":"vdgx_gfSwrtM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n","from joblib import dump\n","\n","# Define MLPClassifier\n","mlp = MLPClassifier(max_iter=200, random_state=42)\n","\n","# Define hyperparameter grid\n","param_grid = {\n","    'hidden_layer_sizes': [(64,), (128,), (64, 32), (128, 64)],\n","    'activation': ['relu', 'tanh'],\n","    'solver': ['adam'],\n","    'alpha': [0.0001, 0.001, 0.01],  # L2 regularization\n","    'learning_rate': ['constant', 'adaptive'],\n","    'batch_size': [32, 64]\n","}\n","\n","# GridSearchCV\n","grid_search_mlp = GridSearchCV(\n","    estimator=mlp,\n","    param_grid=param_grid,\n","    cv=5,\n","    scoring='accuracy',\n","    n_jobs=-1,\n","    verbose=2\n",")\n","\n","# Fit the model\n","grid_search_mlp.fit(X_train, y_train)\n","\n","# Best model\n","best_mlp_model = grid_search_mlp.best_estimator_\n","\n","# Predictions\n","y_pred_train = best_mlp_model.predict(X_train)\n","y_pred_test = best_mlp_model.predict(X_test)\n","\n","# Evaluation\n","print(\"Best Parameters:\", grid_search_mlp.best_params_)\n","print(f\"\\nTrain Accuracy: {accuracy_score(y_train, y_pred_train):.4f}\")\n","print(f\"Test Accuracy: {accuracy_score(y_test, y_pred_test):.4f}\")\n","print(f\"Precision: {precision_score(y_test, y_pred_test):.4f}\")\n","print(f\"Recall: {recall_score(y_test, y_pred_test):.4f}\")\n","print(f\"F1 Score: {f1_score(y_test, y_pred_test):.4f}\")\n","print(\"\\nConfusion Matrix:\")\n","print(confusion_matrix(y_test, y_pred_test))\n","print(\"\\nClassification Report:\")\n","print(classification_report(y_test, y_pred_test))\n","\n","# Save the model\n","dump(best_mlp_model, '/content/drive/My Drive/SLMg77/Models/MLP_model_thesis_Classification.joblib')\n","print(\"\\nMLP model saved.\")\n"],"metadata":{"id":"ZrD2bwLdxqE_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"2ZSPApYf3YIH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n"],"metadata":{"id":"DRsai8373YPa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"jNDoEF2jwskI"},"execution_count":null,"outputs":[]}]}